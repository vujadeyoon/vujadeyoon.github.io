<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Sungjun  Yoon | Publications</title>
    <meta name="author" content="Sungjun  Yoon" />
    <meta name="description" content="Publications by categories in reversed chronological order." />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/ico/github.ico"/>
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://vujadeyoon.github.io/publications/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://vujadeyoon.github.io/"><span class="font-weight-bold">Sungjun</span>   Yoon</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">Main</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/curriculum_vitae/">Curriculum Vitae</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description">Publications by categories in reversed chronological order.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICCVW 2021</abbr></div>

        <!-- Entry bib key -->
        <div id="victor2021pose" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Improving Key Human Features for Pose Transfer</div>
          <!-- Author -->
          <div class="author">Victor-Andrei Ivan, Ionut Mistreanu, Andrei Leica, <a href="https://vujadeyoon.github.io">Sung-Jun Yoon</a>, Manri Cheon, Junwoo Lee, and Jinsoo Oh
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE International Conference on Computer Vision Workshop (ICCVW)</em>,  Oct.  2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Ivan_Improving_Key_Human_Features_for_Pose_Transfer_ICCVW_2021_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>It is still a great challenge in the Pose Transfer task to generate visually coherent images, to preserve the texture of clothes, to maintain the source identity and to realistically generate key human features such as the face or the hands. To tackle these challenges, we first conduct a study to obtain the most robust conditioning labels for this task and the baseline method [??] that we choose. We then improve upon the baseline by including deep source features from an Auto-encoder through an Attention mechanism. Finally we add region discriminators that are focused on key human features, thus obtaining results competitive with the state-of-the-art.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">victor2021pose</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Improving Key Human Features for Pose Transfer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Victor-Andrei, Ivan and Ionut, Mistreanu and Andrei, Leica and Sung-Jun, Yoon and Manri, Cheon and Junwoo, Lee and Jinsoo, Oh}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Computer Vision Workshop (ICCVW)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICCVW 2021}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Ivan_Improving_Key_Human_Features_for_Pose_Transfer_ICCVW_2021_paper.html}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CVPRW 2021</abbr></div>

        <!-- Entry bib key -->
        <div id="manri2021iqa" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Perceptual Image Quality Assessment with Transformers</div>
          <!-- Author -->
          <div class="author">Manri Cheon, <a href="https://vujadeyoon.github.io">Sung-Jun Yoon</a>, Byungyeon Kang, and Junwoo Lee
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW)</em>,  Jun.  2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Cheon_Perceptual_Image_Quality_Assessment_With_Transformers_CVPRW_2021_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we propose an image quality transformer (IQT) that successfully applies a transformer architecture to a perceptual full-reference image quality assessment (IQA) task. Perceptual representation becomes more important in image quality assessment. In this context, we extract the perceptual feature representations from each of input images using a convolutional neural network (CNN) backbone. The extracted feature maps are fed into the transformer encoder and decoder in order to compare a reference and distorted images. Following an approach of the transformer-based vision models, we use extra learnable quality embedding and position embedding. The output of the transformer is passed to a prediction head in order to predict a final quality score. The experimental results show that our proposed model has an outstanding performance for the standard IQA datasets. For a large-scale IQA dataset containing output images of generative model, our model also shows the promising results. The proposed IQT was ranked first among 13 participants in the NTIRE 2021 perceptual image quality assessment challenge. Our work will be an opportunity to further expand the approach for the perceptual IQA task.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">manri2021iqa</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Perceptual Image Quality Assessment with Transformers}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Manri, Cheon and Sung-Jun, Yoon and Byungyeon, Kang and Junwoo, Lee}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CVPRW 2021}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Cheon_Perceptual_Image_Quality_Assessment_With_Transformers_CVPRW_2021_paper.html}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CVPRW 2021</abbr></div>

        <!-- Entry bib key -->
        <div id="jinjin2021iqa" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">NTIRE 2021 Challenge on Perceptual Image Quality Assessment</div>
          <!-- Author -->
          <div class="author">Manri Cheon, <a href="https://vujadeyoon.github.io">Sungjun Yoon</a>, Byungyeon Kang, and Junwoo Lee
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW)</em>,  Jun.  2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Gu_NTIRE_2021_Challenge_on_Perceptual_Image_Quality_Assessment_CVPRW_2021_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/award/Award_NTIRE2021.png" class="btn btn-sm z-depth-0" role="button">AWARD</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper reports on the NTIRE 2021 challenge on perceptual image quality assessment (IQA), held in conjunction with the New Trends in Image Restoration and Enhancement workshop (NTIRE) workshop at CVPR 2021. As a new type of image processing technology, perceptual image processing algorithms based on Generative Adversarial Networks (GAN) have produced images with more realistic textures. These output images have completely different characteristics from traditional distortions, thus pose a new challenge for IQA methods to evaluate their visual quality. In comparison with previous IQA challenges, the training and testing datasets in this challenge include the outputs of perceptual image processing algorithms and the corresponding subjective scores. Thus they can be used to develop and evaluate IQA methods on GAN-based distortions. The challenge has 270 registered participants in total. In the final testing stage, 13 participating teams submitted their models and fact sheets. Almost all of them have achieved much better results than existing IQA methods, while the winning method can demonstrate state-of-the-art performance.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">jinjin2021iqa</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{NTIRE 2021 Challenge on Perceptual Image Quality Assessment}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Manri, Cheon and Sungjun, Yoon and Byungyeon, Kang and Junwoo, Lee}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CVPRW 2021}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Gu_NTIRE_2021_Challenge_on_Perceptual_Image_Quality_Assessment_CVPRW_2021_paper.html}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">award</span> <span class="p">=</span> <span class="s">{Award_NTIRE2021.png}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CVPRW 2020</abbr></div>

        <!-- Entry bib key -->
        <div id="shanxin2020demoireing" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">NTIRE 2020 Challenge on Image Demoireing: Methods and Results</div>
          <!-- Author -->
          <div class="author">Manri Cheon, <a href="https://vujadeyoon.github.io">Sung-Jun Yoon</a>, Byungyeon Kang, and Junwoo Lee
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW)</em>,  Jun.  2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w31/Yuan_NTIRE_2020_Challenge_on_Image_Demoireing_Methods_and_Results_CVPRW_2020_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/award/Award_NTIRE2020.png" class="btn btn-sm z-depth-0" role="button">AWARD</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper reviews the Challenge on Image Demoireing that was part of the New Trends in Image Restoration and Enhancement (NTIRE) workshop, held in conjunction with CVPR 2020. Demoireing is a difficult task of removing moire patterns from an image to reveal an underlying clean image. The challenge was divided into two tracks. Track 1 targeted the single image demoireing problem, which seeks to remove moire patterns from a single image. Track 2 focused on the burst demoireing problem, where a set of degraded moire images of the same scene were provided as input, with the goal of producing a single demoired image as output. The methods were ranked in terms of their fidelity, measured using the peak signal-to-noise ratio (PSNR) between the ground truth clean images and the restored images produced by the participants’ methods. The tracks had 142 and 99 registered participants, respectively, with a total of 14 and 6 submissions in the final testing stage. The entries span the current state-of-the-art in image and burst image demoireing problems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shanxin2020demoireing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{NTIRE 2020 Challenge on Image Demoireing: Methods and Results}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Manri, Cheon and Sung-Jun, Yoon and Byungyeon, Kang and Junwoo, Lee}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CVPRW 2020}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content_CVPRW_2020/html/w31/Yuan_NTIRE_2020_Challenge_on_Image_Demoireing_Methods_and_Results_CVPRW_2020_paper.html}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">award</span> <span class="p">=</span> <span class="s">{Award_NTIRE2020.png}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">KSII TIIS</abbr></div>

        <!-- Entry bib key -->
        <div id="jaeyung2019scaler" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Weighted DCT-IF for Image up Scaling</div>
          <!-- Author -->
          <div class="author">Jae-Yung Lee, <a href="https://vujadeyoon.github.io">Sung-Jun Yoon</a>, Jae-Gon Kim, and Jong-Ki Han
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>KSII Transactions on Internet and Information Systems</em> Feb.  2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://www.itiis.org/digital-library/manuscript/2258" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The design of an efficient scaler to enhance the edge data is one of the most important issues in video signal applications, because the perceptual quality of the processed image is sensitively affected by the degradation of edge data. Various conventional scaling schemes have been proposed to enhance the edge data. In this paper, we propose an efficient scaling algorithm for this purpose. The proposed method is based on the discrete cosine transform-based interpolation filter (DCT-IF) because it outperforms other scaling algorithms in various configurations. The proposed DCT-IF incorporates weighting parameters that are optimized for training data. Simulation results show that the quality of the resized image produced by the proposed DCT-IF is much higher than that of those produced by the conventional schemes, although the proposed DCT-IF is more complex than other conventional scaling algorithms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">jaeyung2019scaler</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Weighted DCT-IF for Image up Scaling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jae-Yung, Lee and Sung-Jun, Yoon and Jae-Gon, Kim and Jong-Ki, Han}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{KSII Transactions on Internet and Information Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{790--809}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3837/tiis.2019.02.017}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{KSII TIIS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{http://www.itiis.org/digital-library/manuscript/2258}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IEEE TIP</abbr></div>

        <!-- Entry bib key -->
        <div id="sungjun2018FRUC" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Hierarchical Extended Bilateral Motion Estimation based Frame Rate Up-Conversion using Learning based Linear Mapping</div>
          <!-- Author -->
          <div class="author">
<a href="https://vujadeyoon.github.io">Sung-Jun Yoon*</a>, Hyun-Ho Kim*, and Munchurl Kim
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Image Processing</em> Dec.  2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/document/8423719" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present a novel and effective learning-based frame rate upconversion (FRUC) scheme, using linear mapping. The proposed learning-based FRUC scheme consists of: 1) a new hierarchical extended bilateral motion estimation (HEBME) method; 2) a light-weight motion deblur (LWMD) method; and 3) a synthesis-based motion-compensated frame interpolation (S-MCFI) method. First, the HEBME method considerably enhances the accuracy of the motion estimation (ME), which can lead to a significant improvement of the FRUC performance. The proposed HEBME method consists of two ME pyramids with a three-layered hierarchy, where the motion vectors (MVs) are searched in a coarse-to-fine manner via each pyramid. The found MVs are further refined in an enhanced resolution of four times by jointly combining the MVs from the two pyramids. The HEBME method employs a new elaborate matching criterion for precise ME which effectively combines a bilateral absolute difference, an edge variance, pixel variances, and an MV difference among two consecutive blocks and its neighboring blocks. Second, the LWMD method uses the MVs found by the HEBME method and removes the small motion blurs in original frames via transformations by linear mapping. Third, the S-MCFI method finally generates interpolated frames by applying linear mapping kernels for the deblurred original frames. In consequence, our FRUC scheme is capable of precisely generating interpolated frames based on the HEBME for accurate ME, the S-MCFI for elaborate frame interpolation, and the LWMD for contrast enhancement. The experimental results show that our FRUC significantly outperforms the state-of-the-art non-deep learning-based schemes with an average of 1.42 dB higher in the peak signal-to-noise-ratio and shows comparable performance with the state-of-the-art deep learning-based scheme.<br>
  * Sung-Jun Yoon and Hyun-Ho Kim contribute equally to the work.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sungjun2018FRUC</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical Extended Bilateral Motion Estimation based Frame Rate Up-Conversion using Learning based Linear Mapping}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sung-Jun, Yoon* and Hyun-Ho, Kim* and Munchurl, Kim}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Image Processing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{27}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5918--5932}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TIP.2018.2861567}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{IEEE TIP}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/8423719}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">MASTER THESIS</abbr></div>

        <!-- Entry bib key -->
        <div id="sungjun2018thesis" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Study on Learning-based Approaches to Video Frame Interpolation using Linear Mapping Kernels and CNN-based Nonlinear Mapping Kernels</div>
          <!-- Author -->
          <div class="author">
<a href="https://vujadeyoon.github.io">Sung-Jun Yoon</a>
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Korea Advanced Institute of Science and Technology (KAIST)</em>,  Feb.  2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://kdrm.kaist.ac.kr/ezpdfwebviewer/ezpdf/customLayout.jsp?encdata=67D4CD8135C7372A39A4274B829ADEF3464FB94188985D30EC8EAAA96535597AE464993BE0419278598BD59B7D4A0373DBD1086053FD9E323EC684C0539E9F055B00F5FD41B0997C" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Frame rate up-conversion, also called video frame interpolation (VFI), is a low-level computer vision problem for generating one ore more intermediate frames between two original consecutive frames in videos. The FRUC problem has been solved for several decades by heuristic approaches, and deep-learning based FRUC has recently been studied. We propose two approaches to FRUC: (i) a learning-based direct linear mapping approach; and (ii) a kernel-based approach using a hierarchical deep convolutional neural network (CNN). We present a novel and effective learning-based FRUC scheme, using linear mapping. The proposed learning-based FRUC scheme consists of (i) a novel hierarchical extended bilateral motion estimation (HEBME) method and (ii) a synthesis-based motion-compensated frame interpolation (S-MCFI) method. We also present a kernel-based FRUC scheme based on a convolution neural network (CNN) where two sets of horizontal and vertical kernels are learned for two consecutive input frames by the proposed hierarchical CNN. The proposed learning-based FRUC scheme consists of (i) kernel estimation and (ii) shift-able local convolution for interpolating intermediate pixels. The shift-able‘ local convolution can yield the estimated kernels that can cover large regions that are often out of the ranges in conventional kernel-based approaches. The experimental results show that our linear mapping-based FRUC significantly outperforms the state-of-the-art schemes which are based on heuristic approaches with average 1.50 dB higher in PSNR and our hierarchical CNN-based FRUC outperforms the state-of-the-art schemes including the latest deep-learning-based FRUC scheme. Specifically, the hierarchical CNN-based FRUC scheme with our proposed shift-able local convolution can interpolate an intermediate frame with high-quality when objects in the original frames have fast motions.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@masterthesis</span><span class="p">{</span><span class="nl">sungjun2018thesis</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Study on Learning-based Approaches to Video Frame Interpolation using Linear Mapping Kernels and CNN-based Nonlinear Mapping Kernels}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sung-Jun, Yoon}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{Korea Advanced Institute of Science and Technology (KAIST)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{MASTER THESIS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{http://kdrm.kaist.ac.kr/ezpdfwebviewer/ezpdf/customLayout.jsp?encdata=67D4CD8135C7372A39A4274B829ADEF3464FB94188985D30EC8EAAA96535597AE464993BE0419278598BD59B7D4A0373DBD1086053FD9E323EC684C0539E9F055B00F5FD41B0997C}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">KCVS</abbr></div>

        <!-- Entry bib key -->
        <div id="sungjun2018FRUD" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Study on Hierarhical CNN based Frame Rate Up-Conversion</div>
          <!-- Author -->
          <div class="author">
<a href="https://vujadeyoon.github.io">Sung-Jun Yoon</a>, Yongwoo Kim, and Munchurl Kim
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The 30th Workshop on Image Processing and Image Understanding (IPIU)</em>,  Feb.  2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.eiric.or.kr/community/post2.php?m=view&amp;gubun=201802&amp;num=13799&amp;pg=1&amp;seGubun=&amp;seGubun1=&amp;SnxGubun=%B1%B8%B5%CE&amp;searchBy=Writer&amp;searchWord=%C0%B1%BC%BA%C1%D8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/award/Award_IPIU_2018.png" class="btn btn-sm z-depth-0" role="button">AWARD</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we propose a frame rate enhancement method using hierarchical convolution neural network. The convolutional neural network is constructed hierarchically, and the convolution operation is performed at the optimal position adaptively, so that the performance is robust against the interpolation of the fast moving object. As a result, compared with the existing ICCV 2017 "Video Frame Interpolation via Adaptive Separable Convolution" algorithm, the improvement was 0.41dB in terms of peak signal-to-noise ratio (PSNR).</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sungjun2018FRUD</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Study on Hierarhical CNN based Frame Rate Up-Conversion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sung-Jun, Yoon and Yongwoo, Kim and Munchurl, Kim}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 30th Workshop on Image Processing and Image Understanding (IPIU)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{KCVS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://www.eiric.or.kr/community/post2.php?m=view&amp;gubun=201802&amp;num=13799&amp;pg=1&amp;seGubun=&amp;seGubun1=&amp;SnxGubun=%B1%B8%B5%CE&amp;searchBy=Writer&amp;searchWord=%C0%B1%BC%BA%C1%D8}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">award</span> <span class="p">=</span> <span class="s">{Award_IPIU_2018.png}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">KSBE</abbr></div>

        <!-- Entry bib key -->
        <div id="sungjun2015scaler" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">An adaptive scaler for UHD video</div>
          <!-- Author -->
          <div class="author">
<a href="https://vujadeyoon.github.io">Sung-Jun Yoon</a>, and Jong-Ki Han
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The Korean Society Of Broad Engineers</em>,  Jul.  2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE06396456&amp;language=ko_KR&amp;hasTopBanner=false" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sungjun2015scaler</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An adaptive scaler for UHD video}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sung-Jun, Yoon and Jong-Ki, Han}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Korean Society Of Broad Engineers}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{KSBE}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE06396456&amp;language=ko_KR&amp;hasTopBanner=false}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 <a href="https://vujadeyoon.github.io" target="_blank">Sungjun Yoon</a>. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

